{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_transforms:\n",
    "    train_transforms = None\n",
    "    test_transforms = None\n",
    "    validation_transforms = None\n",
    "    \n",
    "class image_datasets:\n",
    "    train_data , test_data, valid_data = None, None, None\n",
    "class dataloaders:\n",
    "    trainloader, testloader, validloader = None, None, None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(gpu):\n",
    "    global device\n",
    "    if torch.cuda.is_available() and gpu:\n",
    "        print(\"Changed to GPU mode.\")\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif not torch.cuda.is_available():\n",
    "        print('GPU is not available.')\n",
    "        device = torch.device(\"cpu\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    \n",
    "def load_data(data_dir):\n",
    "    \n",
    "    train_dir = data_dir + '/train'\n",
    "    test_dir = data_dir + '/test'\n",
    "    valid_dir = data_dir + '/valid'\n",
    "    \n",
    "    data_transforms.train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                                           transforms.RandomResizedCrop(224),\n",
    "                                                           transforms.RandomHorizontalFlip(),\n",
    "                                                           transforms.ToTensor(),\n",
    "                                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                                [0.229, 0.224, 0.225])])\n",
    "    data_transforms.test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                                          transforms.CenterCrop(244),\n",
    "                                                          transforms.ToTensor(),\n",
    "                                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                               [0.229, 0.224, 0.225])])\n",
    "    data_transforms.validation_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                                               transforms.CenterCrop(244),\n",
    "                                                               transforms.ToTensor(),\n",
    "                                                               transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                                    [0.229, 0.224, 0.225])])\n",
    "\n",
    "    # TODO: Load the datasets with ImageFolder\n",
    "    image_datasets.train_data = datasets.ImageFolder(train_dir, transform=data_transforms.train_transforms)\n",
    "    image_datasets.test_data = datasets.ImageFolder(test_dir, transform=data_transforms.test_transforms)\n",
    "    image_datasets.valid_data = datasets.ImageFolder(valid_dir, transform=data_transforms.validation_transforms)\n",
    "    \n",
    "    \n",
    "    # TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "    dataloaders.trainloader = torch.utils.data.DataLoader(image_datasets.train_data, batch_size = 64, shuffle=True)\n",
    "    dataloaders.testloader = torch.utils.data.DataLoader(image_datasets.test_data, batch_size = 32)\n",
    "    dataloaders.validloader = torch.utils.data.DataLoader(image_datasets.valid_data, batch_size = 32)\n",
    "    \n",
    "    print(\"Loaded Data\")\n",
    "    return data_transforms, image_datasets, dataloaders\n",
    "\n",
    "\n",
    "def create_model(structure = 'densenet121', dropout = 0.3, lr = 0.003, hidden_units = 512, checkpoint = None):\n",
    "    global model\n",
    "    global criterion\n",
    "    criterion = nn.NLLLoss()\n",
    "    global optimizer\n",
    "    \n",
    "    if checkpoint is None:\n",
    "        output_size = 102\n",
    "    \n",
    "        if structure == 'densenet121':\n",
    "            model = models.densenet121(pretrained=True)\n",
    "            input_size = 1024\n",
    "        elif structure == 'vgg16':\n",
    "            model = models.vgg16(pretrained=True)\n",
    "            input_size = 25088\n",
    "        elif structure == 'vgg13':\n",
    "            model = models.vgg13(pretrained=True)\n",
    "            input_size = 4096\n",
    "    \n",
    "        if not model.classifier is None:\n",
    "            if type(model.classifier) is nn.Linear:\n",
    "                input_size = model.classifier.in_features\n",
    "            else:\n",
    "                input_size = model.classifier[0].in_features\n",
    "            \n",
    "        print(f\"Input size: {input_size}\")\n",
    "        print(\"Created model.\")\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    \n",
    "        model.classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(input_size, hidden_units)),\n",
    "                                                      ('relu1', nn.ReLU()),\n",
    "                                                      ('dropout1', nn.Dropout(p = dropout)),\n",
    "                                                      ('fc2', nn.Linear(hidden_units, output_size)),\n",
    "                                                      ('output', nn.LogSoftmax(dim = 1))\n",
    "                                                     ]))\n",
    "        optimizer = optim.Adam(model.parameters(), lr)\n",
    "    else:\n",
    "        structure = checkpoint['structure']\n",
    "        epochs = checkpoint['epochs']\n",
    "        dropout = checkpoint['dropout']\n",
    "        \n",
    "        if structure == 'densenet121':\n",
    "            model = models.densenet121(pretrained=True)\n",
    "            input_size = 1024\n",
    "        elif structure == 'vgg16':\n",
    "            model = models.vgg16(pretrained=True)\n",
    "            input_size = 25088\n",
    "        elif structure == 'vgg13':\n",
    "            model = models.vgg13(pretrained=True)\n",
    "            input_size = 4096\n",
    "        \n",
    "        model.classifier = checkpoint['classifier']\n",
    "        model.class_to_idx = checkpoint['class_to_idx']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), checkpoint['learning_rate'])\n",
    "        optimizer.load_state_dict(checkpoint['optim_state_dict'])\n",
    "        \n",
    "        print(\"Loaded checkpoint\")\n",
    "        \n",
    "    print(\"Configured model.\")\n",
    "    \n",
    "    \n",
    "    #print(device)\n",
    "    model.to(device)\n",
    "    #return model.to(device)\n",
    "\n",
    "def train(epochs = 3):\n",
    "    epochs = epochs\n",
    "    steps = 0\n",
    "    print_every = 5\n",
    "    print(\"Start to trainning...\")\n",
    "    #process = reset_process(epochs*(len(dataloaders.trainloader)))\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "    \n",
    "        for inputs, labels in dataloaders.trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            steps += 1\n",
    "            log_ps = model.forward(inputs)\n",
    "            loss = criterion(log_ps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            running_loss += loss.item()\n",
    "            #report_process(process, steps)\n",
    "            if steps % print_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    valid_loss, accuracy = validation(model, criterion)\n",
    "                \n",
    "                print(f\"Epochs:{e+1}/{epochs}, \",\n",
    "                      f\"Training:{steps}/{len(dataloaders.trainloader)}, \",\n",
    "                      f\"Training loss:{'%.3f' %(running_loss/print_every)}.. \",\n",
    "                      f\"Validation loss: {'%.3f' %(valid_loss/len(dataloaders.validloader))}, \",\n",
    "                      f\"Validation accuracy: {'%.3f' %(accuracy/len(dataloaders.validloader))}, \")\n",
    "        \n",
    "       \n",
    "    print(\"Total steps:\", steps)\n",
    "                    \n",
    "def validation(model, criterion):\n",
    "    valid_loss = 0\n",
    "    accuracy = 0\n",
    "    for inputs, labels in dataloaders.testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        log_ps = model(inputs).to(device)\n",
    "        loss = criterion(log_ps, labels)\n",
    "        valid_loss += loss.item()\n",
    "                    \n",
    "        ps = torch.exp(log_ps)\n",
    "        top_ps, top_class = ps.topk(1, dim = 1)\n",
    "        equality = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += equality.type(torch.FloatTensor).mean().item()\n",
    "    return valid_loss, accuracy\n",
    "\n",
    "def load_checkpoint(load_path = 'checkpoint.pth'):\n",
    "    if os.path.isfile(load_path):\n",
    "        print(\"Loading checkpoint\")\n",
    "        model = create_model(checkpoint = torch.load(load_path))\n",
    "        \n",
    "        #model = create_model(structure=checkpoint)    \n",
    "        #optimizer.load_state_dict(checkpoint['optim_state_dict'])\n",
    "    else:\n",
    "        print(f\"Can not find the file at {load_path}.\\n Please input the right file path.\")\n",
    "        return _, _\n",
    "    #return model, optimizer\n",
    "\n",
    "def save_checkpoint(save_path, structure, hidden_units, dropout, lr, epochs):\n",
    "    model.class_to_idx = image_datasets.train_data.class_to_idx\n",
    "    #print(model)\n",
    "    checkpoint = {'epochs': epochs,\n",
    "                  'structure': structure,\n",
    "                  'hidden_units': hidden_units,\n",
    "                  'dropout': dropout,\n",
    "                  'learning_rate': lr,\n",
    "                  'state_dict' : model.state_dict(),\n",
    "                  'optim_state_dict' : optimizer.state_dict(),\n",
    "                  'class_to_idx' : model.class_to_idx,\n",
    "                  'classifier' : model.classifier\n",
    "                 }\n",
    "    #print(checkpoint)\n",
    "    print(\"Saving checkpoint\")\n",
    "    torch.save(checkpoint, save_path)\n",
    "\n",
    "def process_image(image_path):\n",
    "    transform = transforms.Compose([transforms.Resize(256),\n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                         std=[0.229, 0.224, 0.225])])\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    \n",
    "    return transform(image)\n",
    "\n",
    "def predict(image, top_k = 1, cat_library_path = 'cat_to_name.json'):\n",
    "    model.to(device)\n",
    "                      \n",
    "    with open(cat_library_path, 'r') as f:\n",
    "        cat_to_name = json.load(f)\n",
    "                      \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        model.eval()\n",
    "        img = image.to(device)\n",
    "        img.unsqueeze_(0)\n",
    "        output = model(img)\n",
    "        \n",
    "        ps = torch.exp(output)\n",
    "        \n",
    "        top_ps, top_class = ps.topk(top_k, dim=1)\n",
    "        top_ps, top_class = top_ps.cpu().numpy(), top_class.cpu().numpy()\n",
    "        \n",
    "        index_to_class = {x: y for y, x in model.class_to_idx.items()}\n",
    "        #print(index_to_class)\n",
    "        #top_class_id = [index_to_class[e] for e in top_class.ravel()]\n",
    "        top_class_name = [cat_to_name[str(index_to_class[e])] for e in top_class.ravel()]\n",
    "        #print(top_class_name)\n",
    "        return top_ps, top_class, top_class_name\n",
    "                  \n",
    "                  \n",
    "def reset_process(total):\n",
    "    pbar = tqdm(total=total, desc=\"Transfer progress\", ncols=100, position=0, leave=True)\n",
    "    return pbar\n",
    "                  \n",
    "def report_process(pbar, process):\n",
    "        pbar.update(process)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "#if __name__ == \"__main__\":\n",
    "    #load_data(\"flowers\")\n",
    "    #create_model(\"vgg13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | pattern 'notebook.ipynb' matched no files\n",
      "[NbConvertApp] Converting notebook Common.ipynb to python\n",
      "[NbConvertApp] Writing 10985 bytes to Common.py\n",
      "[NbConvertApp] Converting notebook Image Classifier Project.ipynb to python\n",
      "[NbConvertApp] Writing 24320 bytes to Image Classifier Project.py\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    !jupyter nbconvert --to python notebook.ipynb *.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
